# System Design - 60 minutes

Overview: This interview covers services architecture
and systems design. You’ll be assessed on your ability to
design a high-level data E2E system while diving deep
into areas like data ingestion, data processing, scalability,
and the data persistence layer. You’ll be evaluated on
your ability to come up with efficient solutions to
open-ended problems by applying your knowledge of
systems theory and product development. This interview
will be conducted using an online whiteboard tool. Our
preferred platform for a virtual whiteboard is HackerRank,
however if there is a tool with similar functionality that you are more comfortable with then please
come prepared with it.

What they looking for:\
● Structure: Ensure you take a systematic approach to building your solution and that you
articulate what you are trying to do and why you are trying to do it.\
● Comprehensiveness: Ensure your approach covers all aspects of the requirements and
tackles any potential edge cases.\
● Feasibility: Ensure your solution is practical and could realistically be implemented.\
● Scalability: Ensure your solution has the capacity to scale as we increase users or
broaden the problem requirements.

Tips:\
● Clarifying Questions: Before jumping in to designing your solution, ensure that you
understand all aspects of the given requirements.\
● Trade Offs: Understand the various tradeoffs of the components in your system and
explain them to your interviewer.\
● Articulate Thought Process: If faced with difficulties, explain your solution approach and
reasoning. This transparency enables interviewers to provide valuable hints and insights.



## Experiences

<details>
<summary> Online </summary>

- You have to track user metrics - how will you develop solution for it - real time vs batch discussion 
Prev Project discussions - data modelling - data collection - transformation - where we will write them? what metrics on real time what batch ? what frequency? - dashboard refresh - frequency 
streaming focussed than batch(Manish Kumar Youtube)

(Blind)
- For system design interview. Question was something like hosting a service then backend db design for services and analytics design for data getting logged.
- Business round was more like business use case specific if there is drop in sales. How will you figure out? What data sources to look for ? Then what will be steps.
- Managerial round was on day to day activities. What’s the architecture? How do you handle conflicts? What were initiatives? What mistakes you made? What did you learn from those?

</details>


## Preparation 

<details>
    <summary>  Resources  </summary>

1. [System Design for Data]([https://www.youtube.com/watch?v=OWeQ_gCNe4k) 
2. System design Interview by Alex - Book
3. Design Data Intensive Application - Book
4. Youtube Videos - Arpit Bhayani, Gaurav Sen 
5. [Medium (Read) - Streamimg Data Pipeline](https://medium.com/@seancoyne/data-engineering-practice-system-design-question-and-solution-streaming-ad32562ba954)


### Videos 
1. [Building a data platform with open source: A $1M+ cost-saving journey](https://www.youtube.com/watch?v=WdQ1hlK57Ys)
</details>


<details>
    <summary>  High Level Componemts </summary>


Let's say you have to Design an e-commerce platfrom related to data side

- Clarify what you are trying to make 
    - What does e-commerce means ? Nykaa, Amazon
    - Are you asking to build transactional or analytical system?
    - Who will be the end consumer?
    - What is the scale of data, what is anticipated scale in upcoming 6 months or a year?
    - Existing systems or services which I should be aware of ?
    - What is the type of data? - Structured, unstructured, semi-structured?
    - Most important feature which I should start with ?

<h4> Back of envelope estimations </h4>

- Scale 
    - Power of 2 
        - 1 Kb 
        - 1 Mb 
        - 1 GB
        - 1 TB
        - 1 PB

- Latency - Microservices 
    - sending data over networks - compression(Json/Protobuff) - encoding (DDIA book)
    - Compression 
    - Multi region copy latency will matter

- Availability 
    - Pipeline criticality - no downtime - 99%
    - Pipeline Uptime
    - Tier 1, Tier 2, Tier 3 - Exception, ROllback implementation 

- Calculate storage requirements 
    - Total Data volume on a daily basis if you can tell
    - no of total users 
    - DAU or MAU 
    - Always round off the number to nearest 100
    - Daily 200 GB for 1 year = 200 * 400 = 8 * 10^4 = 80000 GB = 80 TB Data 
    - How much time you want to keep the data ? Purge? cold system? 
    - no. of seconds in a day ?

<h4> High Level Design - Draw.io </h4>

- Test Cases (CICD)
    
- Input 
    - Data Format
    - Frequency 
    - Schema Evolution (API data specially)
    - PII data or normal data (Governance/Encryption)

- Business Use Case
    - Metrics to track - promotional activity - inventory ? shelf? 
    - How freq will you track ? Batch or real time? 
    - SLA (how much time will you take - 4 hours- rollback)

- Output
    - Target System 
    - Data Retention 
    - Refresh Frequency 
    - Historical Data  

**Summary**
1. Real Time Analytics 
2. Historical Analysis 
3. Scalability (Data + Processing)
4. Flexible data model

<h4> Building a solution </h4>

Incoming Data Sources 
1. API 
2. DB (SQL/ No SQL)
3. Files

- There can be a system that can pick from API and put into KAFKA or can also put directly from API to KAFKA in real time. 
- 6 hour sync in DB -> S3(Raw Layer) -> How will you pull data into S3? what will be Partitioning strategy? 
- Processing Layer -> (Medallion Architecture)
    - Metrics 1 - Near Real time (FLINK/ Spark Streaming) -> will go to Kafka -> UI (superset) or Dashboard
    - Metric 2 - incremental data (hourly or daily folder) after 6 hour sync -> Snowflake DWH (transient or permanent table / view materialised or normal) or go back to No SQL 
    - Business Usecase 
    - Data Modelling is done one time - Fact and dimension writing - distinct values in dimension - snapshot 
 
1. Why Kafka ?
2. Why SQL, No SQL?
3. Ingestion Layer - Pull Data 
4. Scheduling - Cron/ Airflow 
5. CI/CD (Gitlab/ Code coverage/ Test Cases/ Roll Back)
6. Exception Handling (on whole system, Trade off, Fault Tolerance, roll back )


### Drill Down 
1. API 
- Microservices 
- Event Driven Architecture 
- Pull/ Push Mechanisam 
- Authentication (JWT, SAML)
- Design Pattern -> LLD
- LLD (object , class interaction) how will you pull data from API or Files?
- Async Programming (very infreq, multi processing, multi threading)

2. Database (Most Focus)
- SQL, No SQL
- DB Internals 
- Volume Challenges (if volume is increasing day by day where to keep data DB or DWH)
- Optimization - Query and DB 
- Indexing/ Sharding/ Caching/ Materialized view - which column and what indexing
- ACID 
- CAP Theorem
- Constraints/ Normalization/ Denormalization
- Leader Follower Architecture 
- Connection Pull 

3. File Type 
- Parquet/ORC/CSV - which you have used why? what optimizations?
- structured vs unstructured( how will you process, schema evolution)
- Hudi, Iceberg, Delta Table 

4. S3 (80 TB per year - where should we keep? Business - how much do they need?)
- Cost Analysis 
    - Amazon - starting orders in cache - earlier year they keep in different layer 
    - Logs - Purge because volume is too much - 6 months - machine generated 
- DataLake vs Delta Lake 
- Data at Rest Encryption 
- Partitioning (File and DB)

5. Kafka 
- Backpressure 
- offset management ( where it is stored, how, how can we bring it back)
- Broker/ Producer/ Consumer 
- Kafka Connect 
- Topic and its management(why, when replication)
- Auto Commit and Linger Time 
- Exactly once record process( Failure overcome, so that it is dropped, how kafka manages this? there should be no duplication, how will you resolve this?)
- Failure Overcome 
- Replication 

6. Spark Streaming 
If you will you use Kafka , you need streaming, either you use Microservice Architecture or Flink 
- Flink vs Spark Streaming 
    - Late Data Arrival
    - Sliding window 
    - Checkpointing
    - commits
    - stateful vs stateless
    - event time - one semantics at the time of generation - when data arrived or producer system generated data and why, fault tolerance
    - Fault Tolerance  Question: You have Kafka with retention of 6 hour for logs - Failure of Spark Streaming, retention is over- now how will you ensure logs are there? will you increase retention? - linked in post suggested 3 days - but kafka cluster will be full
    - Performance optimization 
    
7. Processing layer (Not much focus here)
- Dimensional Modelling 
- Lakehouse Architecture 


8. Spark 
- on which platform will you run this ?
- data transformation
- all questions


9. Medallion Architecture
- GOLD Layer 
    - PII data (RBAC Permission) row level and column level 
    - How will you put encryption - UDF in spark - Encryption logic - how to decrypt 
    - Unity Catalog( Databricks)
    

Dimension Modelling 
- ER diagram Practice 
- Fact and Dimension Table 
- Ecommerce (user, sales, inventory)
- Ride sharing App 
- Finance Domain (credit card details) 
- Health Domain 

10. Scheduling/ Orchestration 
- Airflow 
- Internal Working 
- Type of executor 
- DAG/ TASK
- operators/ Sensor
- Custom operator 
- Xcom
- Backfill 
- Pools
- Automation/ Microservices

11. Docker & Kubernetes 


Not Required
- Login management 
- CDN 
- Tokenisation 
- Maps 
- Ride Sharing on Data Side not on Application Side 

</details>


## Questions 

<details>
<summary> 1. How would you make sure API calls with rate limits ? </summary>

</details>

<details>
<summary>2. Large volume of data in S3 which cannot be pulled directly into system - how will you proecess it ? </summary>

</details>


<details>
<summary> 3. Imagine you have millions of IoT devices, emitting sensor data every second. Your goal is to collect this data and process it in real time to detect anomalies, and store both raw and processed data in a scalable data store. How would you design an end to end solution? </summary>

Questions that can be asked [5min - 10 min]

1. Main goal anomaly detection or other analytics needs (predictive maintenance, user behaviour analyis?)
2. Is data structured, semi-structured or unstructured?
3. Data comes in at constant rate or are there spikes in data ? 
4. Need to implement data encryption at rest or in transit?
5. Are there any specific compliance or regulatory requirements for storing sensor data, such as GDPR, HIPPA ?
6. How many devices do you expect initially, how quickly will that number grow? 

</details> <!-- Question 3. -->

<details>
<summary> 4. Let's say you encounter a Spark pipeline performing poorly, how do you go about identifying the issues and optimizing?</summary>

- Step 1: Understand the Symptoms
    Start by identifying the exact issue:
    1. Is the job slow overall or just certain stages?
    2. Is it failing or just taking too long?
    3. Is it CPU-bound, memory-bound, or I/O-bound?

    You can use:
    1. Spark UI (local or in your cluster manager like YARN/EMR/Databricks)
    2. Logs (driver and executor logs)
    3. Metrics dashboards (e.g., Ganglia, CloudWatch, Prometheus)

- Step 2: Profile the Spark Job
    Inspect the Spark UI:
    1. Stages & Tasks: Look for skewed stages, long-running tasks, or failed ones.
    2. Shuffle & Spill: Excessive shuffle and disk spill are red flags.
    3. Job DAG: Check if it's too complex or has unnecessary stages.
    4. Task Distribution: Are all cores utilized? Are some executors idle?

- Step 3: Review the Code and Transformations
    Look for:
    1. Wide transformations like groupBy, join, distinct, repartition — these trigger shuffles.
    2. UDFs — especially Python UDFs in PySpark — which are black-boxes to Spark.
    3. Collect or broadcast misuse.
    4. Unnecessary caching or missing persistence.

- Step 4: Check Data Issues
    1. Data Skew: One or a few keys have too much data (e.g., one country has 90% of rows). Fix via:
    - Salting the key
    - Aggregating before joining
    2. Small files: Can lead to too many tasks. Coalesce or compact beforehand.
    3. Data size: Check partition sizes — aim for 100–200MB per partition.

- Step 5: Tune Spark Configurations
    1. Memory Usage:
    - By default split, execution (for computation) and storage (for caching data)
    - Increase executor memory or storage fraction `(spark.executor.memory, spark.memory.storageFraction)`
    - Also, check spark.executor.memory to set the memory per executor—make sure it fits within your cluster’s node capacity.
    2. Parallelism:
        - Set `spark.sql.shuffle.partitions` appropriately (not default 200 for big data) based on your data size and cluster resources.
        - Tune `spark.default.parallelism`
        - 2-4 tasks per CPU core
        - How many cores are available in your cluster?
    3. Executor and Driver Settings: 
        - Set spark.executor.cores and spark.executor.instances to control how many executors run and how many cores each uses.
        For example, if a node has 16 cores, you might set 5 cores per executor to leave room for OS and other processes.
        - The driver (spark.driver.memory) also needs enough memory, especially for collecting results or running heavy operations.
    3. Garbage Collection: Long GC pauses can kill performance.
    4. Broadcast joins:
    If one side of a join is small (<10MB), enable broadcast joins
    Manually broadcast if Spark doesn’t auto-detect

Step 6: Infrastructure Considerations
Are your executors under-provisioned?
Is auto-scaling working effectively?
Are disk or network IO bottlenecks showing up in metrics?

- Step 7: Iterate & Test
    - After each change, re-run and compare:
        1. Job duration
        2. Shuffle size
        3. Stage/task run times
        4. Executor utilization

</details> <!-- Question 4. -->

<details>
<summary> 5. How do you manage the complexity of a pipeline with tons of transformations? </summary>
</details> <!-- Question 5. -->

<details>
<summary> 6. How do you go about testing this pipeline? </summary>
</details> <!-- Question 6. -->


<details>
<summary> 7. Design shopping cart for website </summary>

1. What is the user count ? 500 K 
2. Active user count ? 100K
    - system needs to be scalable 
3. Traffic spikes in the year or month? 
4. Stateless or stateful (state is maintained on refresh) - cart should be stateful 
5. Region (US, Europe, APAC) for data governance 
6. On prem, on cloud 

### Design 
 
- Load balancer for spikes 
- AutoScaling for compute 

- caching mechanism 
    1. Redis caching, a database with large cache, super performant 
        - Cons manage an extra component and cost
- VPC router - will route to the right region 

Data Pipeline for 
1. Data Source 
2. Batch or Live 
3. Frequency ? 
4. Data Size 
   - 450 GB /month 
5. Already have an system in place? you need to move to cloud from spark
6. Data customers? 
    - BI users
    - DS (ML model)
    - Operational User 

Design 
1. Landing Area - S3 - all data comes here
2. Spark based processing system in AWS? 
3. Store in S3 again 
4. Snowflake - serverless for SQL part 
5. Notebooks for ML people 
6. Orchestration - Airflow 

</details>  <!-- Question 7. -->

<details>
<summary> 8. Design ETL pipeline to ingest data from multiple external APIs 
Handle Schema Evolution </summary>

Airflow @daily vs @once triggered 
Slow sql to optimize
failure handling, retry logic , partitioning 
how will you handle large file in GBs
asked to find top 10 user by event frequency - constraint was optimized for memory
what if streaming data type change mid way
generator functions 

System Design 
Real time Data Pipeline for click stream events 
Ensure fault toleranc 
where deduplication logic 
store 1 billion records 
z ordering 

Behaviour 
- You take full ownership of failing project 
- What do you if deadline is missed because of your code 

</details>

<details>
<summary> 9. Netflix Clickstream Data Pipeline</summary>

[Design Data pipeline for Netflix metrics monitoring for click stream or playback data](https://www.youtube.com/watch?v=53tcAZ6Qda8)

### Product Metrics

#### Questions 
1. What metrics are you looking for? You have to define
    - User engagement from click stream 
        - User churn - if they are not visiting, what is their interest
        - Path Analysis - navigation path customer is taking 
          - set a target that they will click on the promotion 
          - what is blocking them? is it too long mey be 7-8 clicks?
        - Behavior Profiling - 
    - Playback
        - trending series
        - when they click on pause? because most people binge watch if it is interesting 
        - time it take for a user to watch 1 hour show may be they are taking 3 hours, can use this for recommendation
2. Keep the solution Generic - do you want to use some specific technologies?

### Pipeline Design 

1. Data Capture 
2. Streaming/Batch 
3. Processing 
4. Storage 
5. Analytics

6. Metrics 
   - Number of subscribers = 200M 
   - 50% Active Daily = 100 M
   - 1 day = 100k seconds
   - 1 day = 100M/100k = 1000 users/sec , cannot assume for every sec 
   - 80% traffic-20 of time rule = 100M users/20K sec = 5000 users/sec
   - user generate 10 events per sec = 50K events per sec - this can be more than this when a popular series come in - traffic spikes 

- Geographical distribution is something we should take into account for Netflix's scale -> Cloud front distribution

- Push and pull models 
    - Push - agents running on server - quickly overwelhm your infra - you don't have to pull
    - Pull - You decide when you want to poll for more data, your insights might be lost sometimes if you are polling late - timing is critical for some promotions

- API Gateway - where servers can push data to 
- Lambda -> you can collect and preprocess data 
- Kakfa -> has buffer, if consumer is not online it can pick up - can store data for max 7 days
- Spark -> distributed computing platform - spark streaming module which can plug into Kafka to extract data - works in microbatches not sub sec latency 
- Flink -> real time distributed computing platform - milli second latency
- DataLake Why? 
    - Store in ObjectStore 
    - Raw Layer 
    - Processed 
    - Need data stored over time - for analytics 
    - in S3 you can run queries directly using Athena, straightway 
    - After Flink you can put in NO SQL DB like Dyanamo DB - no schema - fast read/writes 
    - If you use Relational DB for storing it will be the bottleneck - pipeline will be as fast as DB 

1. What is the difference between row based file format & columnar file format? And why columnar-based file formats such as parquet or orc are favoured for analytics?
    - Row-Based File Formats store data in a sequential, row-by-row manner. Think of it like a spreadsheet where each row represents a complete record, and all the values for that record (across all columns) are stored together. Examples include CSV, JSON, and traditional relational database storage formats. When you read data from a row-based format, you typically access all the columns for a given row at once, even if you only need a subset of the data.

    - Columnar File Formats, on the other hand, store data by column rather than by row. Each column's data is stored together, separate from the other columns. Formats like Apache Parquet and ORC (Optimized Row Columnar). When you read from a columnar format, you can efficiently access just the specific columns you need without loading the entire dataset into memory.

    - Key Differences
        1. `Storage Organization`: Row-based formats keep all data for a single record together, while columnar formats group data by column, allowing for more efficient access to specific fields across many records.
        2. `Read Efficiency`: In row-based formats, querying a single column often means scanning through entire rows, loading unnecessary data. Columnar formats let you read only the columns you're interested in, which is much faster for analytical queries.
        3. `Compression`: Columnar formats often achieve better compression because data within a `single column tends to be more similar (e.g., a column of dates or numbers)` compared to `mixed data types in a row`. This reduces storage size and speeds up data transfer.
        4. `Write Performance`: `Row-based formats are generally better for write-heavy workloads` (like transactional systems) because `appending a new record is straightforward`. Columnar formats can be `slower for writes since data needs to be organized by column`.
    
    - Why Columnar Formats Like Parquet and ORC Are Favored for Analytics
        which often involve aggregating or analyzing specific columns across large datasets (think data warehouses or big data processing). Here's why they shine in this context:

        1. Selective Column Access: target only a subset of columns (e.g., summing sales figures or filtering by date). Columnar formats allow systems to read just the relevant columns, skipping irrelevant data, which drastically reduces I/O and speeds up query execution.
        2. Better Compression and Encoding: Since columnar data is more homogeneous, it compresses better using techniques like run-length encoding or dictionary encoding. For example, Parquet and ORC can store repeated values efficiently, saving space and improving read performance.
        3. Partitioning and Predicate Pushdown: Formats like Parquet support metadata and partitioning, enabling query engines (like Apache Spark or Hive) to skip entire chunks of data that don't match query conditions. This means less data is scanned, further boosting performance.
        4. Scalability for Big Data: In distributed systems, columnar formats work well with parallel processing frameworks. They allow tasks to be split by column or data block, making it easier to handle massive datasets efficiently.
       
        In contrast, `row-based formats are more suited for transactional systems (OLTP) where entire records are frequently inserted, updated, or retrieved as a whole`.

2. Different compression techniques such as snappy, biz2 and LZO. And which one to choose?
    Compression techniques are used to reduce the size of data, which helps save storage space and can speed up data transfer or processing, especially in big data environments. Each method has trade-offs in terms of `compression ratio (how much it reduces size)`, `speed of compression/decompression`, and `computational overhead`.
    1. Snappy:
        - Snappy is a compression library developed by Google, designed for high-speed compression and decompression with a `focus on low latency`. It `prioritizes speed `over achieving the smallest possible file size.
        - Compression Ratio: Moderate. It doesn't compress data as tightly as some other algorithms, but it still reduces size significantly for many data types.
        - Speed: Very fast for both compression and decompression, making it ideal for real-time or near-real-time applications.
        - Use Case: Often used in big data frameworks like Apache Hadoop, Spark, and Kafka, where quick compression/decompression is critical during data processing or streaming.
        - CPU Usage: Relatively low, as it avoids complex algorithms to maintain speed.`
    2. Bzip2:
        Bzip2 is a compression algorithm that uses the Burrows-Wheeler transform and Huffman coding to achieve high compression ratios. It’s `more focused on minimizing file size` than on speed.
        - Compression Ratio: High. It typically produces smaller files compared to Snappy or LZO, especially for text-heavy data.
        - Speed: Slower for both compression and decompression compared to Snappy or LZO. 
        - Use Case: Suitable for scenarios where storage space is a primary concern and speed is less critical, such as archiving data or compressing files for long-term storage.
        - CPU Usage: Higher than Snappy or LZO due to its complex algorithm, which can be a bottleneck in resource-constrained environments.
    3. LZO (Lempel-Ziv-Oberhumer):
        - LZO is a lightweight compression algorithm focused on speed, similar to Snappy, but with a slightly different balance between compression ratio and performance.
        - Compression Ratio: Moderate, often comparable to Snappy, though it can vary depending on the data type. It’s generally not as tight as Bzip2.
        - Speed: Very fast decompression, often faster than Snappy, but compression speed can be slightly slower than Snappy in some cases.
        - Use Case: Commonly used in real-time systems or embedded environments `where decompression speed is critical`, such as in file systems (e.g., SquashFS) or data transfer protocols.
        - CPU Usage: Low to moderate, designed to be lightweight and efficient even on less powerful hardware.
        
        Which One to Choose?
        - Choose Snappy if you’re working in a big data or analytics environment (e.g., with Hadoop, Spark, or Kafka) where speed is critical, and you’re dealing with frequent read/write operations. Snappy is often the default choice for columnar file formats like Parquet or ORC in these systems because it balances speed and compression well for intermediate data processing. It’s ideal when you need low latency and can afford slightly larger file sizes.
        - Choose Bzip2 if your `primary goal is to minimize storage space` and you’re not constrained by time or CPU resources. 
        - Choose LZO if you need extremely fast decompression and are working in a system where read performance is more important than write performance.
    
    - Additional Considerations
        1. Data Type: The effectiveness of each algorithm can depend on the nature of your data. For example, Bzip2 excels with text data due to its ability to exploit patterns, while Snappy and LZO are more general-purpose.
        2. Framework Compatibility: If you’re using tools like Apache Spark or Hadoop, check their default or recommended compression codecs. Snappy is widely supported and often the default in these ecosystems for a reason.
        3. Splittability: In distributed systems, ensure the compression method supports splitting compressed files for parallel processing. Snappy and LZO are typically splittable when used with formats like Parquet, while Bzip2 is splittable by design but slower, which might negate the benefit.

</details>

<details>
<summary> </summary>

- Videos Watched  
   1. https://www.youtube.com/watch?v=NZ_-2RB-NU0
   2. https://www.youtube.com/watch?v=w8xWTIFU4C8


1. Ingestion 
- Analytics Service (Managed service like Amplitude or Posthog)
    - time series log of page views or user data  - appended to historical data 
    - cloud based - cannot directly connect with our inhouse services like Queue 
- Database 
    - point in time data for state of our application - can be changes 
    - Batch Job - pulls from DB, transform it and put into our Storage Layer 
2. Transformation 
    - ETL is the batch job 
    - if huge data in DB -> batch job might take lot of time -> scale horizontally -> use spark (distributed processing engine)-> deploys work to multiple clusters
    - remember batch pipeline will run run multiple times - everyday 
    ### Batch Ingestion Strategies 
    1. Full Database Load with Timestamping

        Load the entire database into the data lake on a regular schedule, such as daily, and tagging each load with a timestamp. This approach ensures that you maintain a complete historical record of the data at different points in time.

    - Advantages: It allows for historical analysis since every state of the database is preserved. If you need to analyze trends or changes over time, this method provides all the necessary data snapshots.
    - Disadvantages: The major downside is redundancy. You're storing unchanged data repeatedly, which increases storage costs and puts a heavy load on the ETL (Extract, Transform, Load) pipeline due to processing the full dataset each time.
    - Best Use Case: historical data integrity is critical, and storage costs or processing times are not primary concerns, such as in `regulatory compliance or long-term trend analysis`.
    2. Full Database Reload with Overwrite
        
        In this approach, you drop the existing table in the data lake and reload the entire current state of the database each time the batch job runs. Data lake always reflects the latest snapshot of the database without retaining historical data.

    - Advantages: It minimizes storage costs, The data lake remains a mirror of the current database state, which can be simpler to manage.
    - Disadvantages: You lose historical data, Additionally, the ETL pipeline still processes the entire dataset each time, leading to high processing overhead.
    - Best Use Case: where only the current state matters, and historical data is irrelevant or stored elsewhere, such as in operational reporting systems focused on real-time data.
    3. Incremental Load with Updated-At Tracking

        Loading only the data that has changed since the last batch job, typically by tracking an "updated_at" field in the database. Only records updated within a specific time frame (e.g., the last day or two) are ingested into the data lake, using an upsert operation (update if exists, insert if new).

    - Advantages: It significantly reduces the amount of data processed by the ETL pipeline, improving speed and reducing costs. This method is more efficient for large datasets where only a small portion changes frequently.
    - Disadvantages: It introduces complexity in ensuring data consistency. If the "updated_at" field isn't maintained correctly (e.g., due to manual edits), the data lake and database can become out of sync. Additionally, job failures might result in missing data for certain time periods.
    - Best Use Case: systems with frequent updates where efficiency is key, and the database schema supports reliable timestamp tracking, such as in transactional systems with regular data modifications.

    4. Incremental Load with Ingestion Tracking
    
        Building on the incremental load, this method adds an "ingested_at" field alongside "updated_at" to track when data was last ingested into the data lake. Data is only ingested if it was updated after the last ingestion, ensuring no gaps in data due to job failures, as on job failure we will not update the ingestion time.

    - Advantages: This approach mitigates the risk of data gaps caused by job failures by providing a clear record of ingestion times. It enhances the reliability of incremental loads.
    - Disadvantages: It still faces challenges with manual data changes that don't update timestamps correctly. It also requires transactional integrity to ensure the "ingested_at" field is only updated when data is successfully ingested, adding complexity to the ETL process.
    - Best Use Case: Ideal for mission-critical systems where data completeness is essential, and job reliability might be a concern, such as in financial or customer data warehousing.
    
    Implementation Considerations
    To implement these batch pipeline strategies effectively, consider the following tools and practices along with some additional recommendations:

    - ETL Frameworks: Use distributed processing frameworks like Apache Spark to handle large-scale data ingestion and transformation. Spark can parallelize tasks across multiple nodes, significantly reducing processing time for full or incremental loads.
    - Scheduling and Orchestration: Employ tools like Apache Airflow to schedule and monitor batch jobs. Airflow allows you to define dependencies between tasks (e.g., ensuring ingestion completes before transformation) and provides visibility into job success or failure.
    - Data Lake Storage: Opt for scalable storage solutions like AWS S3 or Hadoop Distributed File System (HDFS) for your data lake. These systems are optimized for storing vast amounts of unstructured data and integrate well with processing frameworks like Spark.
    - Latency and Scalability: Address latency concerns by scaling horizontally with Spark clusters. `For incremental strategies, ensure your database indexing supports quick queries on "updated_at" or "ingested_at" fields to minimize extraction time`.
    - Error Handling and Monitoring: Implement robust error handling in your ETL pipelines to manage job failures, especially for incremental loads with ingestion tracking. Use transactions to ensure data consistency, and set up alerts in Airflow for failed jobs.
    ### Writing to a Queue 
    - Writing data to a queue facilitates real-time or near-real-time data ingestion into a data lake, bypassing the delays of batch processing.
    - Within your application, whenever data is written to the database, simultaneously write the same data or a relevant event to a queue.
    - The queue acts as a buffer between data sources (like databases or third-party services) and the data lake, allowing for asynchronous processing and reducing direct load on source systems.
    - Analytics Service -> webhook handler(API) -> Queue -> Flink (process data from a queue) -> Data Lake
    - Handling Third-Party Services: For external sources like cloud-based analytics services (e.g., Amplitude), use webhooks to bridge the gap. Set up an HTTP server to receive data from the service and write it to the queue.
    - Alternatively, use a cloud-based queue (e.g., Amazon Kinesis Data Streams) that the Analytics service can directly access, eliminating the need for a middleman.
    - Ensure the queue system is reliable and can handle high throughput to avoid data loss or bottlenecks. If using a cloud-based queue, verify security and access controls. Dual-writing to the queue and database requires transactional consistency to prevent discrepancies.
3. Storage Layer for DS 
    - HDFS, S3
4. Snowflake is a cloud-based data warehouse solution that integrates data storage (data    lake) and distributed processing capabilities.
    - Snowflake can connect directly to queues (e.g., cloud-based queues) and ingest data without additional middleware.   
    - Many analytics services have built-in integrations with Snowflake, allowing direct data writes to the Snowflake instance, eliminates the need for queues or webhook handlers for external data sources.
    - Snowflake internally incorporates concepts similar to traditional tools (e.g., distributed processing, data lake storage), providing a managed version of these 
    functionalities.
    - Using Snowflake may involve trade-offs such as vendor lock-in and costs associated with a SaaS solution. 


| **Aspect**                  | **Apache Kafka**                                                                 | **Traditional Messaging Queues (e.g., RabbitMQ, SQS)**                          |
|-----------------------------|---------------------------------------------------------------------------------|--------------------------------------------------------------------------------|
| **Data Persistence**        | Stores data as logs in topics for a set retention period; supports replay.      | Messages are transient, often deleted after consumption; limited replay.       |
| **Consumption Pattern**       | Pub-sub model; where producers publish messages to topics, and multiple consumers or consumer groups can subscribe to those topics. One message can be accessed by many consumers - useful where multiple systems analyze the same data.   | Point-to-point or limited pub-sub; typically one consumer per message, with message often removed after delivery.        |
| **Message Routing** | Kafka is organised into mutiple queues each queue can have topics and partitions. Producer decides which queue the data goes to; Less overhead on Kafka cluster, hence high throughput;    | Uses Exchange which take in all messages and route them to queues, it can also route one msg to mutiple queues to replicate fan out.  |
| **Scalability/Throughput**  | Handles millions of messages/sec; partitions for distributed processing.        | Scalable but optimized for lower-latency, smaller-scale message passing.        |
| **Use in Data Warehousing** | Ideal for streaming ingestion into data lakes; supports real-time pipelines.    | Better for task queuing or event notifications; less suited for core pipelines. |
| **Durability/Fault Tolerance** | High durability with data replication across brokers; robust recovery.         | Durable with acknowledgments, but less focus on long-term data retention.      |
| **Complexity/Management**   | More complex; requires distributed cluster setup (brokers, ZooKeeper).          | Simpler for small-scale use; less overhead for basic message passing.           |
| **Acknowledment**   | Has offset; Kafka logs an offset of how many messages a consumer has; whenever a consumer needs more data it reads from that offset from the queue, when it is done it commits the offset back to let Kafka know that it successfully processed that data; great with batches of data with small events. Note: Kafka doesn't "send" messages actively to consumers; instead, consumers pull messages from topics at their own pace. |  Has ACK - sent ACK to Queue - send data to another consumer if ACK is not received   - good for long running tasks that need ACK|



Non-Functional 
1. Low Latency loading 
2. Handle Scale of data 


</details >